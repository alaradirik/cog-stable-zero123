import os
import glob
import shutil
import subprocess
from typing import List

import torch
import trimesh
import numpy as np
from diffusers import DDIMScheduler, DiffusionPipeline
from cog import BasePredictor, Input, Path

from image_utils import preprocess
from file_utils import download_and_extract


MODEL_URLS_MAP = {
    "stabilityai-sdxl-base-1.0-fp16": "https://weights.replicate.delivery/default/stable-zero123/stabilityai-sdxl-base-1.0-fp16.tar"
}

class Predictor(BasePredictor):
    def setup(self) -> None:
        for MODEL_PATH, MODEL_URL in MODEL_URLS_MAP.items():
            if not os.path.exists(MODEL_PATH):
                download_and_extract(MODEL_URL, MODEL_PATH)

        self.device = (
            torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
        )

        self.scheduler = DDIMScheduler(
            beta_start=0.00085,
            beta_end=0.012,
            beta_schedule="scaled_linear",
            clip_sample=False,
            set_alpha_to_one=False,
        )

        self.pipe = DiffusionPipeline.from_pretrained(
            MODEL_PATH,
            scheduler=self.scheduler,
            torch_dtype=torch.float16,
            variant="fp16",
        ).to(self.device)

    def predict(
        self,
        image: Path = Input(description="Input image, optional.", default=None),
        prompt: str = Input(
            description="Prompt to generate image from, only used if no input image is provided.", 
            default="an orange cat"
        ),
        num_views: int = Input(
            description="Number of views to generate.",
            ge=4, le=12, default=8, 
        ),
        guidance_scale: float = Input(
            description="Scale of guidance loss for SDXL. Higher values will make the model focus more on the prompt.",
            default=7.5, ge=1, le=50,
        ),
        num_inference_steps: int = Input(
            description="Number of denoising steps to run SDXL.",
            default=100, ge=1, le=200,
        ),
        num_multiview_steps: int = Input(
            description="Number of inference steps to run for multi-view image generation.",
            default=100, ge=1, le=200,
        ),
        num_3d_max_steps: int = Input(
            description="Maximum number of training steps for 3D generation.",
            default=600, ge=100, le=1000,
        ),
        remove_background: bool = Input(
            description="Whether to remove image background. Set to false only if uploading image with removed background.",
            default=True
        ),
        return_3d: bool = Input(
            description="Whether to return a 3D object as output. If set to false, only returns multi-views generated by multi-view diffusion backbone.",
            default=True
        ),
    ) -> List[Path]:
        if os.path.exists("/src/outputs"):
            shutil.rmtree("/src/outputs")
        
        # Use image instead of prompt
        if image is not None:
            if remove_background:
                bg_removed_img_path = preprocess(image_path=str(image), remove_bg=remove_background)
            else:
                bg_removed_img_path = str(image)
        else:
            # sdxl text to image generation
            generated_img = self.pipe(
                prompt=prompt,
                guidance_scale=guidance_scale,
                num_inference_steps=num_inference_steps,
            ).images[0]
            
            generated_img_path = os.path.join("/tmp/generated.png")
            generated_img.save(generated_img_path)
            bg_removed_img_path = preprocess(image_path=generated_img_path, remove_bg=remove_background)

        if return_3d:
            config = "threestudio/configs/stable-zero123.yaml"
            os.system(f"python threestudio/launch_3d.py --config {config} data.image_path={bg_removed_img_path} \
                trainer.max_steps={num_3d_max_steps}")
            
            export_obj_path = f"/src/outputs/save/it{num_3d_max_steps}-export/model.obj"
            mesh = trimesh.load(export_obj_path, process=False)

            out_mesh_path = "/tmp/mesh.glb"
            out_video_path = f"/src/outputs/it{num_3d_max_steps}-test.mp4"
            mesh.export(out_mesh_path)
            output = [Path(out_mesh_path), Path(out_video_path)]
            
            if os.path.exists("/src/lightning_logs"):
                shutil.rmtree("/src/lightning_logs")
            return output
        else:
            config = "threestudio/custom/threestudio-mvimg-gen/configs/stable-zero123.yaml"
            os.system(f"python threestudio/launch.py --config {config} data.image_path={bg_removed_img_path} \
                system.num_inference_steps={num_multiview_steps} data.random_camera.n_test_views={num_views}"),
            
            output_paths = []
            for file in glob.glob("/src/outputs/it0-test/*"):
                if file.endswith(".png"):
                    output_paths.append(Path(file))
                    
            if os.path.exists("/src/lightning_logs"):
                shutil.rmtree("/src/lightning_logs")
            return output_paths